{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gm1t78vLpyrU",
        "colab_type": "text"
      },
      "source": [
        "# # Retinopathy detection using SVM and CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5uv_z90Vycu",
        "colab_type": "text"
      },
      "source": [
        "We begin by importanting the different datasets we may need, such as pandas, sklearn, or keras. You can notice the importation of Augmentor. it's a library developped to artificillay generate new images by applying random transformation to our original dataset (https://augmentor.readthedocs.io/en/master/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18u9BO0beN8r",
        "colab_type": "code",
        "outputId": "fa7842af-7ed3-43cc-d5c1-db6b277091d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        }
      },
      "source": [
        "!pip install Augmentor"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Augmentor\n",
            "  Downloading https://files.pythonhosted.org/packages/e0/cd/088b7a425aadccbb0d142e40439e37fe69fbd71b67ef2ca27cb1bffcf682/Augmentor-0.2.7-py2.py3-none-any.whl\n",
            "Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.6/dist-packages (from Augmentor) (0.16.0)\n",
            "Requirement already satisfied: tqdm>=4.9.0 in /usr/local/lib/python3.6/dist-packages (from Augmentor) (4.28.1)\n",
            "Collecting Pillow>=5.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/5c/0e94e689de2476c4c5e644a3bd223a1c1b9e2bdb7c510191750be74fa786/Pillow-6.2.1-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 3.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from Augmentor) (1.17.4)\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: Pillow, Augmentor\n",
            "  Found existing installation: Pillow 4.3.0\n",
            "    Uninstalling Pillow-4.3.0:\n",
            "      Successfully uninstalled Pillow-4.3.0\n",
            "Successfully installed Augmentor-0.2.7 Pillow-6.2.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "nqXtXLK1pysV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import glob\n",
        "from keras.preprocessing.image import load_img\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.utils import resample, shuffle\n",
        "from keras.models import Sequential\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.utils import np_utils\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import pickle\n",
        "import Augmentor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CG7FW2IAqDf5",
        "colab_type": "code",
        "outputId": "ebbd85c0-9569-4486-c2c7-915be9436c26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "#I connect this notebook to my Google Drive to access the different pictures\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True)\n",
        "os.chdir('/content/gdrive/My Drive/fintech/fintech_DR')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWb1-bUAWqfl",
        "colab_type": "text"
      },
      "source": [
        "DATA PREPROCESSING :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lm_e8A6xpysd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('training_set.pkl', 'rb') as f:\n",
        "        training_set = pickle.load(f)\n",
        "with open('test_set.pkl', 'rb') as f:\n",
        "        test_set = pickle.load(f)\n",
        "training_set, val_set=train_test_split(training_set, test_size=0.05,stratify=training_set.label,random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiQx_rEhXP5o",
        "colab_type": "text"
      },
      "source": [
        "We notice here what will be the major challenge we will encounter : an unbalanced dataset. Here, we see that more tan 72% of our set is constitued of images of healthy people. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qKPB2L8pytP",
        "colab_type": "code",
        "outputId": "519dc5e9-3c9b-4a58-e06e-06ed263e2e80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "training_set.label.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    832\n",
              "2    174\n",
              "1     91\n",
              "3     27\n",
              "4     16\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3PTeuc2cDNx",
        "colab_type": "code",
        "outputId": "aebbbf96-bcce-43eb-97c0-0916094d6ee7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "source": [
        "plt.figure(figsize = (10,5))\n",
        "sns.distplot(training_set['label'])\n",
        "plt.title(\"Distribution of DR levels in the training set\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Distribution of DR levels in the training set')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAFNCAYAAAAkdeqeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEoLClIiIiEgIClMiIiIiIfx/Oa5wDjAYwpIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKMJJluNpyth",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels_train_0 = training_set[training_set.label==0]\n",
        "labels_train_1 = training_set[training_set.label==1]\n",
        "labels_train_2 = training_set[training_set.label==2]\n",
        "labels_train_3 = training_set[training_set.label==3]\n",
        "labels_train_4 = training_set[training_set.label==4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0PH78__g5pW",
        "colab_type": "text"
      },
      "source": [
        "We place the images corresponding to each level disease in a new folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8oVGP6RpyvP",
        "colab_type": "code",
        "outputId": "66c81e09-6d70-494c-a55f-00fc0768999e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        }
      },
      "source": [
        "files=labels_train_0.filename\n",
        "for file in files:\n",
        "    img = load_img('images/'+file) # this is a PIL image\n",
        "    img.save(\"images/train/label_0/\"+file)\n",
        "files=labels_train_1.filename\n",
        "for file in files:\n",
        "    img = load_img('images/'+file) # this is a PIL image\n",
        "    img.save(\"images/train/label_1/\"+file)\n",
        "files=labels_train_2.filename\n",
        "for file in files:\n",
        "    img = load_img('images/'+file) # this is a PIL image\n",
        "    img.save(\"images/train/label_2/\"+file)\n",
        "files=labels_train_3.filename\n",
        "for file in files:\n",
        "    img = load_img('images/'+file) # this is a PIL image\n",
        "    img.save(\"images/train/label_3/\"+file)\n",
        "files=labels_train_4.filename\n",
        "for file in files:\n",
        "    img = load_img('images/'+file) # this is a PIL image\n",
        "    img.save(\"images/train/label_4/\"+file)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-7199383d401c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels_train_0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'images/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# this is a PIL image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"images/train/label_0/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels_train_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    108\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    109\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'L'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2571\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mimage\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mSee\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mconcept\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmodes\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2572\u001b[0;31m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mimage\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2573\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0mbytes\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mother\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mraw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2574\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: cannot identify image file 'images/18523_left.jpeg'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AafUYsYMpyvf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p = Augmentor.Pipeline(\"images/train/label_1/\",output_directory=\"output\") \n",
        "p.flip_left_right(0.5) \n",
        "p.greyscale(0.1) \n",
        "p.rotate180(0.3) \n",
        "p.skew(0.4, 0.5) \n",
        "p.zoom(probability = 0.2, min_factor = 0.9, max_factor = 1.1) \n",
        "p.process()\n",
        "p.sample(741) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbXJXAEXpyv-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p = Augmentor.Pipeline(\"images/train/label_2/\",output_directory=\"output\") \n",
        "p.flip_left_right(0.5) \n",
        "p.greyscale(0.1) \n",
        "p.rotate180(0.3) \n",
        "p.skew(0.4, 0.5) \n",
        "p.zoom(probability = 0.2, min_factor = 0.9, max_factor = 1.1) \n",
        "p.process()\n",
        "p.sample(658) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaUknLp_pywK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p = Augmentor.Pipeline(\"images/train/label_3\",output_directory=\"output\") \n",
        "p.flip_left_right(0.5) \n",
        "p.greyscale(0.1) \n",
        "p.rotate180(0.3) \n",
        "p.skew(0.4, 0.5) \n",
        "p.zoom(probability = 0.2, min_factor = 0.9, max_factor = 1.1) \n",
        "p.process()\n",
        "p.sample(805) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WplE_j1wpywN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p = Augmentor.Pipeline(\"images/train/label_4\",output_directory=\"output\") \n",
        "p.flip_left_right(0.5) \n",
        "p.greyscale(0.1) \n",
        "p.rotate180(0.3) \n",
        "p.skew(0.4, 0.5) \n",
        "p.zoom(probability = 0.2, min_factor = 0.9, max_factor = 1.1) \n",
        "p.process()\n",
        "p.sample(816) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fifIE6MCpywS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files=test_set.filename\n",
        "for file in files:\n",
        "    img = load_img('images/'+file) # this is a PIL image\n",
        "    img.save(\"images/test/\"+file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEAiFjjppywt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files=val_set.filename\n",
        "for file in files:\n",
        "    img = load_img('images/'+file) # this is a PIL image\n",
        "    img.save(\"images/val/\"+file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcFR_u4xpywX",
        "colab_type": "code",
        "outputId": "72f1485a-d1fd-46fe-cb75-6a4c80af225d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "labels_val_0 = val_set[val_set.label==0]\n",
        "labels_val_1 = val_set[val_set.label==1]\n",
        "labels_val_2 = val_set[val_set.label==2]\n",
        "labels_val_3 = val_set[val_set.label==3]\n",
        "labels_val_4 = val_set[val_set.label==4]\n",
        "val_set.label.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    44\n",
              "2     9\n",
              "1     5\n",
              "4     1\n",
              "3     1\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-70s9uc2pywb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files=labels_val_0.filename\n",
        "for file in files:\n",
        "    img = load_img('images/'+file) # this is a PIL image\n",
        "    img.save(\"images/val/label_0/\"+file)\n",
        "files=labels_val_1.filename\n",
        "for file in files:\n",
        "    img = load_img('images/'+file) # this is a PIL image\n",
        "    img.save(\"images/val/label_1/\"+file)\n",
        "files=labels_val_2.filename\n",
        "for file in files:\n",
        "    img = load_img('images/'+file) # this is a PIL image\n",
        "    img.save(\"images/val/label_2/\"+file)\n",
        "files=labels_val_3.filename\n",
        "for file in files:\n",
        "    img = load_img('images/'+file) # this is a PIL image\n",
        "    img.save(\"images/val/label_3/\"+file)\n",
        "files=labels_val_4.filename\n",
        "for file in files:\n",
        "    img = load_img('images/'+file) # this is a PIL image\n",
        "    img.save(\"images/val/label_4/\"+file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-jVMJtOWrRb7",
        "colab": {}
      },
      "source": [
        "#I first augmented the validation set also, but it increased the processing time of the CNN\n",
        "\"\"\"\n",
        "p = Augmentor.Pipeline(\"images/val/label_1/\",output_directory=\"output\") \n",
        "p.flip_left_right(0.5) \n",
        "p.greyscale(0.1) \n",
        "p.rotate180(0.3) \n",
        "p.skew(0.4, 0.5) \n",
        "p.zoom(probability = 0.2, min_factor = 0.9, max_factor = 1.1) \n",
        "p.process()\n",
        "p.sample(39) \n",
        "\n",
        "p = Augmentor.Pipeline(\"images/val/label_2/\",output_directory=\"output\") \n",
        "p.flip_left_right(0.5) \n",
        "p.greyscale(0.1) \n",
        "p.rotate180(0.3) \n",
        "p.skew(0.4, 0.5) \n",
        "p.zoom(probability = 0.2, min_factor = 0.9, max_factor = 1.1) \n",
        "p.process()\n",
        "p.sample(35) \n",
        "\n",
        "p = Augmentor.Pipeline(\"images/val/label_3/\",output_directory=\"output\") \n",
        "p.flip_left_right(0.5) \n",
        "p.greyscale(0.1) \n",
        "p.rotate180(0.3) \n",
        "p.skew(0.4, 0.5) \n",
        "p.zoom(probability = 0.2, min_factor = 0.9, max_factor = 1.1) \n",
        "p.process()\n",
        "p.sample(43) \n",
        "\n",
        "p = Augmentor.Pipeline(\"images/val/label_4/\",output_directory=\"output\") \n",
        "p.flip_left_right(0.5) \n",
        "p.greyscale(0.1) \n",
        "p.rotate180(0.3) \n",
        "p.skew(0.4, 0.5) \n",
        "p.zoom(probability = 0.2, min_factor = 0.9, max_factor = 1.1) \n",
        "p.process()\n",
        "p.sample(43) \n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1mzNtU8pywx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creation of a numpy array gathering all the images of the augmented training set\n",
        "train=[]\n",
        "train_labels=[]\n",
        "for myFile in glob.glob(\"images/train/label_0/*.jpeg\"):\n",
        "    image = cv2.imread (myFile)\n",
        "    image = cv2.resize(image,(300,300))\n",
        "    train.append(image)\n",
        "    train_labels.append(0)\n",
        "for myFile in glob.glob(\"images/train/label_1/output/*.jpeg\"):\n",
        "    image = cv2.imread (myFile)\n",
        "    image = cv2.resize(image,(300,300))\n",
        "    train.append(image)\n",
        "    train_labels.append(1)\n",
        "for myFile in glob.glob(\"images/train/label_2/output/*.jpeg\"):\n",
        "    image = cv2.imread (myFile)\n",
        "    image = cv2.resize(image,(300,300))\n",
        "    train.append(image)\n",
        "    train_labels.append(2)\n",
        "for myFile in glob.glob(\"images/train/label_3/output/*.jpeg\"):\n",
        "    image = cv2.imread (myFile)\n",
        "    image = cv2.resize(image,(300,300))\n",
        "    train.append(image)\n",
        "    train_labels.append(3)\n",
        "for myFile in glob.glob(\"images/train/label_4/output/*.jpeg\"):\n",
        "    image = cv2.imread (myFile)\n",
        "    image = cv2.resize(image,(300,300))\n",
        "    train.append(image)\n",
        "    train_labels.append(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KaItge2pyw9",
        "colab_type": "code",
        "outputId": "9aad7dba-1b28-4ef1-dc8c-1c247356b8bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4160"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmCMAYDIpyxE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#we also create a numpy array with the images of the testing set, and their corresponding labels\n",
        "test_labels = []\n",
        "test=[]\n",
        "files_0 = test_set[test_set.label==0].filename\n",
        "files_1 = test_set[test_set.label==1].filename\n",
        "files_2 = test_set[test_set.label==2].filename\n",
        "files_3 = test_set[test_set.label==3].filename\n",
        "files_4 = test_set[test_set.label==4].filename\n",
        "for myFile in files_0:\n",
        "    image = cv2.imread (\"images/test/\"+myFile)\n",
        "    image = cv2.resize(image,(300,300))\n",
        "    test.append(image)\n",
        "    test_labels.append(0)\n",
        "for myFile in files_1:\n",
        "    image = cv2.imread (\"images/test/\"+myFile)\n",
        "    image = cv2.resize(image,(300,300))\n",
        "    test.append(image)\n",
        "    test_labels.append(1)\n",
        "for myFile in files_2:\n",
        "    image = cv2.imread (\"images/test/\"+myFile)\n",
        "    image = cv2.resize(image,(300,300))\n",
        "    test.append(image)\n",
        "    test_labels.append(2)\n",
        "for myFile in files_3:\n",
        "    image = cv2.imread (\"images/test/\"+myFile)\n",
        "    image = cv2.resize(image,(300,300))\n",
        "    test.append(image)\n",
        "    test_labels.append(3)\n",
        "for myFile in files_4:\n",
        "    image = cv2.imread (\"images/test/\"+myFile)\n",
        "    image = cv2.resize(image,(300,300))\n",
        "    test.append(image)\n",
        "    test_labels.append(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmxlzVeOpyxH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#same for the validation set\n",
        "val_labels = []\n",
        "val=[]\n",
        "for myFile in glob.glob(\"images/val/label_0/*.jpeg\"):\n",
        "    image = cv2.imread (myFile)\n",
        "    image = cv2.resize(image,(300,300))\n",
        "    val.append(image)\n",
        "    val_labels.append(0)\n",
        "for myFile in glob.glob(\"images/val/label_1/*.jpeg\"):\n",
        "    image = cv2.imread (myFile)\n",
        "    image = cv2.resize(image,(300,300))\n",
        "    val.append(image)\n",
        "    val_labels.append(1)\n",
        "for myFile in glob.glob(\"images/val/label_2/*.jpeg\"):\n",
        "    image = cv2.imread (myFile)\n",
        "    image = cv2.resize(image,(300,300))\n",
        "    val.append(image)\n",
        "    val_labels.append(2)\n",
        "for myFile in glob.glob(\"images/val/label_3/*.jpeg\"):\n",
        "    image = cv2.imread (myFile)\n",
        "    image = cv2.resize(image,(300,300))\n",
        "    val.append(image)\n",
        "    val_labels.append(3)\n",
        "for myFile in glob.glob(\"images/val/label_4/*.jpeg\"):\n",
        "    image = cv2.imread (myFile)\n",
        "    image = cv2.resize(image,(300,300))\n",
        "    val.append(image)\n",
        "    val_labels.append(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPeKU1EEsIJ9",
        "colab_type": "text"
      },
      "source": [
        "## MODEL TRAINING :\n",
        "Now we fit a convolutional neural network model on the images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PJaYVZdpyxN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num = 5\n",
        "epochs = 10\n",
        "bs = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-f2Y71-pyxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# transform the label into categorical values\n",
        "val_labels=np_utils.to_categorical(val_labels,num)\n",
        "train_labels=np_utils.to_categorical(train_labels,num)\n",
        "val=np.array(val)\n",
        "train=np.array(train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xk4z_YYhvHfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def kappa_loss(y_pred, y_true, y_pow=2, eps=1e-10, N=5, bsize=256, name='kappa'):\n",
        "    \"\"\"A continuous differentiable approximation of discrete kappa loss.\n",
        "        Args:\n",
        "            y_pred: 2D tensor or array, [batch_size, num_classes]\n",
        "            y_true: 2D tensor or array,[batch_size, num_classes]\n",
        "            y_pow: int,  e.g. y_pow=2\n",
        "            N: typically num_classes of the model\n",
        "            bsize: batch_size of the training or validation ops\n",
        "            eps: a float, prevents divide by zero\n",
        "            name: Optional scope/name for op_scope.\n",
        "        Returns:\n",
        "            A tensor with the kappa loss.\"\"\"\n",
        "\n",
        "    with tf.name_scope(name):\n",
        "        y_true = tf.to_float(y_true)\n",
        "        repeat_op = tf.to_float(tf.tile(tf.reshape(tf.range(0, N), [N, 1]), [1, N]))\n",
        "        repeat_op_sq = tf.square((repeat_op - tf.transpose(repeat_op)))\n",
        "        weights = repeat_op_sq / tf.to_float((N - 1) ** 2)\n",
        "    \n",
        "        pred_ = y_pred ** y_pow\n",
        "        try:\n",
        "            pred_norm = pred_ / (eps + tf.reshape(tf.reduce_sum(pred_, 1), [-1, 1]))\n",
        "        except Exception:\n",
        "            pred_norm = pred_ / (eps + tf.reshape(tf.reduce_sum(pred_, 1), [bsize, 1]))\n",
        "            \n",
        "        hist_rater_a = tf.reduce_sum(pred_norm, 0)\n",
        "        hist_rater_b = tf.reduce_sum(y_true, 0)\n",
        "    \n",
        "        conf_mat = tf.matmul(tf.transpose(pred_norm), y_true)\n",
        "    \n",
        "        nom = tf.reduce_sum(weights * conf_mat)\n",
        "        denom = tf.reduce_sum(weights * tf.matmul(\n",
        "            tf.reshape(hist_rater_a, [N, 1]), tf.reshape(hist_rater_b, [1, N])) /\n",
        "                              tf.to_float(bsize))\n",
        "    \n",
        "        return nom / (denom + eps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pm2P92cppyxa",
        "colab_type": "code",
        "outputId": "ec582a22-e4ec-45f1-d41b-c215ab217d2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 631
        }
      },
      "source": [
        "#CNN\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3,3), padding='same', activation='relu', input_shape = (300,300,3)))\n",
        "model.add(Conv2D(32,(3,3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(64,(3,3), padding='same', activation='relu'))\n",
        "model.add(Conv2D(64,(3,3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "    \n",
        "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
        "model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(1024, (3, 3), padding='same', activation='relu'))\n",
        "model.add(Conv2D(1024, (3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "    \n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(output_dim= num, activation='softmax'))\n",
        "model.compile(optimizer=adam(lr=0.0001),loss=kappa_loss, metrics=[\"accuracy\"])\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-18-b3bafe7964ec>:17: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=5)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "2L3W1tEWpyxb",
        "colab_type": "code",
        "outputId": "04b0bb96-519f-4a5e-87fb-41701aea8f1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "H = model.fit(train,train_labels,batch_size=bs,\n",
        "                        validation_data=(val,val_labels),\n",
        "                        epochs=epochs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 4160 samples, validate on 60 samples\n",
            "Epoch 1/10\n",
            "4160/4160 [==============================] - 4408s 1s/step - loss: 5.8921 - acc: 0.2702 - val_loss: 7.7701 - val_acc: 0.5667\n",
            "Epoch 2/10\n",
            " 128/4160 [..............................] - ETA: 1:11:03 - loss: 6.7484 - acc: 0.2188"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_e0B0cRsELS",
        "colab_type": "text"
      },
      "source": [
        "RESULTS :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMYN3b78pyxe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights('images/first_model_last.h5')\n",
        "test=np.array(test)\n",
        "y_pred=model.predict_classes(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "rWhbPlNEpyxh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#confusion matrix\n",
        "\n",
        "print(confusion_matrix(test_labels,y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwqDhkZ_pyxm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#classification report\n",
        "\n",
        "print(classification_report(test_labels,y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}